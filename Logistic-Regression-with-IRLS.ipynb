{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with IRLS\n",
    "This is an implementation of logistic regression in Python using only NumPy. Maximum likelihood estimation is performed using the method of [iteratively re-weighted least squares (IRLS)](https://en.wikipedia.org/wiki/Iteratively_reweighted_least_squares).\n",
    "\n",
    "\n",
    "\n",
    "#### Contents\n",
    "1. [Data Ingestion](#Ingestion)\n",
    "2. [Model Specification](#Specification)\n",
    "3. [Model Fitting](#Fitting)\n",
    "4. [Complete Algorithm and Analysis](#Complete)\n",
    "5. [Sources](#Sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Ingestion'></a>\n",
    "### 1. Data Ingestion\n",
    "The read_dataset() function defined here can be used to read numerical data and create a LogisticModel. The LogisticModel class will be defined further below.\n",
    "\n",
    "We will first walk through the theory, algorithm and Python code before piecing it all together in the LogisticModel fit() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_dataset(path, name='logistic', data_only = False):\n",
    "    \n",
    "    \"\"\"   \n",
    "    Given a .csv file path, separates the responsevector y from the data matrix X.\n",
    "    Assumes all columns have headings, are numerical, and the response vector is the first column.\n",
    "    Returns an instance of LogisticModel with the following attributes:\n",
    "        name: provided name for model\n",
    "        varnames: tuple of variable names\n",
    "        y: the response vector,\n",
    "        X: the predictor matrix, with an additional dummy variable of 1's for the intercept coefficient\n",
    "        \n",
    "    Alternatively, returns the numpy arrays only as a tuple (y,X)\n",
    "    \"\"\"\n",
    "        \n",
    "    data_struc = np.genfromtxt(path, dtype=float, names=True, delimiter=\",\")\n",
    "    data_array = data_struc.view((float, len(data_struc.dtype.names)))\n",
    "    split_data = np.split(data_array, indices_or_sections=[1], axis=1)\n",
    "    varnames = data_struc.dtype.names\n",
    "    y = split_data[0].flatten()\n",
    "    X = np.concatenate((np.ones_like(split_data[0].flatten(), dtype='float64')[:, np.newaxis], split_data[1]), axis=1)\n",
    "    \n",
    "    if data_only:\n",
    "        return (y,X)\n",
    "    else:\n",
    "        return(LogisticModel(name,varnames,y,X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Specification'></a>\n",
    "### 2. Model Specification\n",
    "For logistic regression, we model the probability of each $Y_{i}$ conditioned on the $m$ explanatory variables as the outcome of a Bernoulli-distributed random variable:\n",
    "\n",
    "$$Y_{i}\\mid x_{1,i},...,x_{m,i}\\sim \\mathrm{Bernoulli}(p_{i})$$\n",
    "\n",
    "Each Bernoulli has a single parameter, $p_{i}$, the probability of a success and expected value.\n",
    "\n",
    "The model is specified using the logit transformation so that the predicted log-odds is a linear function of the explanatory variables, $\\mathbf{x}$, and the predicted probability will be between 0 and 1:\n",
    "\n",
    "$$\\log\\frac{p(\\mathbf{x}_{i})}{1-p(\\mathbf{x}_{i})} = \\mathbf{w}^{T}\\mathbf{x}_{i}$$\n",
    "\n",
    "$$p(\\mathbf{x}_{i}) = \\frac{1}{1+e^{-\\mathbf{w}^{T}\\mathbf{x}_{i}}}$$\n",
    "\n",
    "where $\\mathbf{w}$ is a vector of size $m+1$ containing the coefficients and intercept.\n",
    "\n",
    "\n",
    "#### Python:\n",
    "```python\n",
    "# y is the response vector,\n",
    "# X is the predictor matrix, with an additional dummy variable of 1's for the intercept coefficient    \n",
    "\n",
    "w = np.array([0]*X.shape[1], dtype='float64') # create our coefficient vector\n",
    "y_bar = np.mean(y)\n",
    "w_init = math.log(y_bar/(1-y_bar)) # our intitial estimate of the coefficients\n",
    "h = w_init + X.dot(w) # create a vector of linear predictors\n",
    "p = 1/(1+np.exp(-h)) # create a vector of fitted values\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Fitting'></a>\n",
    "### 3. Model Fitting\n",
    "\n",
    "I’ve used the method of Iteratively Reweighted Least Squares (IRLS) to find the maximum likelihood estimate. In this case, IRLS is equivalent to Newton's method, a second-order optimization algorithm.\n",
    "\n",
    "Assuming $n$ independent Bernoulli trials, we have a combined likelihood function for our training data:\n",
    "\n",
    "$$L(\\mathbf{w}) = \\prod_{i=1}^{n}p(\\mathbf{x}_{i})^{y_{i}}(1-p(\\mathbf{x}_{i})^{1-y_{i}})$$\n",
    "\n",
    "and the negative log-liklihood, which we seek to minimize:\n",
    "\n",
    "$$\\mathrm{NLL}(\\mathbf{w})=-\\sum_{i=1}^{n}y_{i}\\log p_{i}+(1-y_{i})\\log (1-p_{i})$$\n",
    "\n",
    "We can be sure that the algorithm will converge to a unique NLL because [the function is strictly convex](http://qwone.com/~jason/writing/convexLR.pdf). Newton’s method consists of taking a series of $k$ \"Newton steps\" of size $-\\mathbf{H}_{k}^{-1}\\mathbf{g}_{k}$, where $\\mathbf{g}$ is the gradient and $\\mathbf{H}$ is the Hessian of $\\mathrm{NLL}$:\n",
    "\n",
    "$$\\mathbf{g} = \\frac{d}{d\\mathbf{w}}f(\\mathbf{w})= \\sum_{i=1}^{n}(p_{i}-y_{i})\\mathbf{x}_{i}=\\mathbf{X}^T(\\mathbf{p}-\\mathbf{y})$$\n",
    "\n",
    "$$\\mathbf{H} = \\frac{d}{d\\mathbf{w}}g(\\mathbf{w})^T=\\sum_{i=1}^{n}(\\nabla_{\\mathbf{w}}p_{i})\\mathbf{x}_{i}^T=\\sum_{i=1}^{n}p_i(1-p_i)\\mathbf{x}_i\\mathbf{x}_i^T=\\mathbf{X}^T\\mathbf{SX}$$\n",
    "\n",
    "$$\\mathbf{S}=\\mathrm{diag}(p_i(1-p_i))$$\n",
    "\n",
    "$\\mathbf{S}$ is a diagonal weighting matrix that simplifies each iteration to solving a weighted least squares problem. Each sample will be repeatedly re-weighted inverse to its estimated variance, $p_i(1-p_i)$ (also the derivative of $p$ with respect to the linear predictor). Our original Newton steps can be simplified:\n",
    "\n",
    "$$\\mathbf{w}_{k+1}=\\mathbf{w}_k-\\mathbf{H}^{-1}\\mathbf{g}_k$$\n",
    "\n",
    "$$\\mathbf{w}_{k+1}=(\\mathbf{X}^T\\mathbf{S}_k\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{S}_k\\mathbf{z}_k$$\n",
    "\n",
    "where $\\mathbf{z}$ is a \"working response\" vector for our weighted least squares problem:\n",
    "\n",
    "$$z_{ki}=\\mathbf{w}^T_k\\mathbf{x}_i+\\frac{y_i-p_{ki}}{p_{ki}(1-p_{ki})}$$\n",
    "\n",
    "#### Python:\n",
    "```python\n",
    "s = p*(1-p) # calculate vector of variances\n",
    "S = np.diag(s) # calculate the diagonal matrix\n",
    "\n",
    "# calculate the working response vector, avoiding division by zero\n",
    "arb_small = np.ones_like(s, dtype='float64')*.000000001\n",
    "z = eta + np.divide((y-mu), s, out=arb_small, where=s!=0)\n",
    "\n",
    "# calculate the new coefficients\n",
    "Xt = np.transpose(X)\n",
    "XtS = Xt.dot(S)\n",
    "XtSX = XtS.dot(X)\n",
    "inverse_of_XtSX = np.linalg.inv(XtSX)\n",
    "inverse_of_XtSX_Xt = inverse_of_XtSX.dot(Xt)\n",
    "inverse_of_XtSX_XtS = inverse_of_XtSX_Xt.dot(S)\n",
    "w = inverse_of_XtSX_XtS.dot(z)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='Complete'></a>\n",
    "### 4. Complete Algorithm and Analysis\n",
    "The complete algorithm will be placed in the fit() method of the LogisticModel class, along with some logic to track and determine if the series converges.\n",
    "\n",
    "We'll also add a summary() method for the statistics and and a predict() method for new test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticModel(object):\n",
    "    \"\"\"A logistic regression model for fitting and predicting binary response data.\n",
    "    \n",
    "    Attributes:\n",
    "        name: provided name of model\n",
    "        varnames: tuple of variable names\n",
    "        y: the response vector,\n",
    "        X: the predictor matrix, with an additional dummy variable of 1's for the intercept coefficient   \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, varnames, y, X):\n",
    "        self.name = name\n",
    "        self.varnames = varnames\n",
    "        self.y = y\n",
    "        self.X = X\n",
    "\n",
    "    def fit(self, iterations=25):\n",
    "        \"\"\"\n",
    "        Given a response vector (y), training data matrix (X), runs the IRLS algorithm to the specified number of iterations.\n",
    "        Returns a dictionary containing the coefficients \n",
    "        \"\"\"\n",
    "\n",
    "        w = np.array([0]*self.X.shape[1], dtype='float64')\n",
    "        y_bar = np.mean(self.y)\n",
    "        w_init = math.log(y_bar/(1-y_bar))\n",
    "        self.converged = False\n",
    "        nll_sequence = []\n",
    "        for i in range(iterations):\n",
    "            h = self.X.dot(w)\n",
    "            p = 1/(1+np.exp(-h))\n",
    "            p_adj = p\n",
    "            p_adj[p_adj==1.0] = 0.99999999\n",
    "            nll = -(1-self.y.dot(np.log(1-p_adj)))+self.y.dot(np.log(p_adj))\n",
    "            nll_sequence += [nll]\n",
    "            \n",
    "            if i>1:\n",
    "                if not self.converged and abs(nll_sequence[-1]-nll_sequence[-2])<.000001:\n",
    "                    self.converged = True\n",
    "                    self.converged_k = i+1\n",
    "            \n",
    "            s = p*(1-p)\n",
    "            S = np.diag(s)\n",
    "            arb_small = np.ones_like(s, dtype='float64')*.000001\n",
    "            z = h + np.divide((self.y-p), s, out=arb_small, where=s!=0)\n",
    "            Xt = np.transpose(self.X)\n",
    "            XtS = Xt.dot(S)\n",
    "            XtSX = XtS.dot(self.X)\n",
    "            inverse_of_XtSX = np.linalg.inv(XtSX)\n",
    "            inverse_of_XtSX_Xt = inverse_of_XtSX.dot(Xt)\n",
    "            inverse_of_XtSX_XtS = inverse_of_XtSX_Xt.dot(S)\n",
    "            w = inverse_of_XtSX_XtS.dot(z)\n",
    "                                                \n",
    "        self.nll = nll\n",
    "        self.nll_sequence = nll_sequence                                                      \n",
    "        self.w=w\n",
    "        \n",
    "        if not self.converged:\n",
    "            print('Warning: IRLS failed to converge. Try increasing the number of iterations.')\n",
    "        \n",
    "        return(self)\n",
    "    \n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Prints a formatted table of the model coefficients \n",
    "        \"\"\"\n",
    "        \n",
    "        if not hasattr(self, 'w'):\n",
    "            print('LogisticModel has not been fit.')\n",
    "            return(None)\n",
    "        \n",
    "        coef_labels = ['---------------','<Intercept>']+list(self.varnames[1:])\n",
    "        estimates = ['---------------']+list(self.w)\n",
    "        \n",
    "        # This table will eventually contain more metrics\n",
    "        table_dic = dict(zip(coef_labels, estimates))\n",
    "        \n",
    "        coef_str = ' + '.join(self.varnames[1:])+'\\n'\n",
    "        \n",
    "        print('\\n'+self.name+': logistic regression')\n",
    "        print('\\n{} ~ {}'.format(self.varnames[0], coef_str))\n",
    "        print('\\033[1m'+\"{:<15} {:<15}\".format('Coefficient','Estimate')+'\\033[0m')\n",
    "        for k, v in sorted(table_dic.items()):\n",
    "            label = v\n",
    "            print(\"{:<15} {:<15}\".format(k, label))\n",
    "        if not self.converged:\n",
    "            print('\\nWarning: IRLS failed to converge. Try increasing the number of iterations.')\n",
    "        else:\n",
    "            print('\\nConverged in {} iterations (IRLS)'.format(self.converged_k))\n",
    "        \n",
    "        return(None)\n",
    "        \n",
    "\n",
    "    def predict(self, X, use_probability = False):\n",
    "        \"\"\"\n",
    "        Given the fitted model and a new sample matrix, X, \n",
    "        returns an array (y) of predicted log-odds (or optionally the probabilities).\n",
    "        \"\"\"\n",
    "        \n",
    "        if not hasattr(self, 'w'):\n",
    "            print('LogisticModel has not been fit.')\n",
    "            return(None)\n",
    "                \n",
    "        pred = X.dot(self.w)\n",
    "        \n",
    "        if use_probability:\n",
    "            odds = np.exp(pred)\n",
    "            pred = odds / (1 + odds)\n",
    "        \n",
    "        return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read our example training datasets and fit each of them to a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = ['fieldgoals', 'juice', 'gold']\n",
    "data = [read_dataset('datasets/'+example+'.csv', name=example) for example in examples]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset.fit(iterations=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize convergence of the NLL and see that the algorithm doesn't require many iterations to converge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAFRCAYAAACc+BKVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x222415d7b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(3, sharex=True, sharey=False, figsize=(9,5))\n",
    "axes[0].set_title('Convergence of Negative Log Likelihood (NLL)')\n",
    "plt.xlabel('iteration')\n",
    "f.text(.05, 0.5, 'NLL', ha='center', va='center', rotation='vertical');\n",
    "\n",
    "for i in range(3):\n",
    "    axes[i].plot(np.arange(len(data[i].nll_sequence)),data[i].nll_sequence, label=data[i].name+' dataset')\n",
    "    axes[i].text(.97, .75, data[i].name+' dataset', transform=axes[i].transAxes, ha='right')\n",
    "    axes[i].locator_params(nbins=2, axis='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summaries of each of the fitted models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fieldgoals: logistic regression\n",
      "\n",
      "Success ~ Yards + Week\n",
      "\n",
      "\u001b[1mCoefficient     Estimate       \u001b[0m\n",
      "--------------- ---------------\n",
      "<Intercept>     6.299689734335034\n",
      "Week            -0.0524336078191799\n",
      "Yards           -0.1127354275434901\n",
      "\n",
      "Converged in 8 iterations (IRLS)\n"
     ]
    }
   ],
   "source": [
    "data[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "juice: logistic regression\n",
      "\n",
      "Growth ~ pH + Nisin + Temp + Brix\n",
      "\n",
      "\u001b[1mCoefficient     Estimate       \u001b[0m\n",
      "--------------- ---------------\n",
      "<Intercept>     -7.246333840412728\n",
      "Brix            -0.31173234862940336\n",
      "Nisin           -0.066276262143294\n",
      "Temp            0.1104223950074471\n",
      "pH              1.885950986253122\n",
      "\n",
      "Converged in 8 iterations (IRLS)\n"
     ]
    }
   ],
   "source": [
    "data[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gold: logistic regression\n",
      "\n",
      "Gold ~ As + Sb + Lineament\n",
      "\n",
      "\u001b[1mCoefficient     Estimate       \u001b[0m\n",
      "--------------- ---------------\n",
      "<Intercept>     -7.609650868692922\n",
      "As              1.2046492650019085\n",
      "Lineament       3.1972564925535014\n",
      "Sb              1.420954188973844\n",
      "\n",
      "Converged in 12 iterations (IRLS)\n"
     ]
    }
   ],
   "source": [
    "data[2].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of predicting new sample responses with the read_dataset() function and predict() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96195407,  0.97240465,  0.35067621,  0.02940531,  0.56176085,\n",
       "        0.75815753,  0.13940303,  0.07039647,  0.01166177,  0.00191276,\n",
       "        0.10981691,  0.00337951,  0.13385971,  0.24290651,  0.02448657,\n",
       "        0.75615076,  0.01934562,  0.29819405,  0.21170375])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = read_dataset('datasets/juice_test.csv', name='logistic', data_only = True)[1]\n",
    "data[1].predict(test_X, use_probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Sources'></a>\n",
    "### 5. Sources\n",
    "1. [*Machine Learning: A Probabilistic Perspective* by Kevin R Murphy](https://www.cs.ubc.ca/~murphyk/MLbook/)\n",
    "2. [GLM Lecture Notes by Germán Rodríguez](http://data.princeton.edu/wws509/notes)\n",
    "3. [Logistic Regression and Newton’s Method Lecture Notes by Cosma Shalizi](http://www.stat.cmu.edu/~cshalizi/402/lectures/14-logistic-regression/lecture-14.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
